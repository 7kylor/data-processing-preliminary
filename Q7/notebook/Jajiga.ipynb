{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39tfTgmcbQUl"
      },
      "source": [
        "<h1 align=center style=\"line-height:200%;color:#0099cc\">\n",
        "<font color=\"#0099cc\">\n",
        "How Much Per Night?\n",
        "</font>\n",
        "</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJuhMbbHY7-f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ast\n",
        "import warnings\n",
        "from typing import Dict, List\n",
        "import subprocess, sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "MAX_THREADS = os.cpu_count() or 8\n",
        "FAST_MODE = True\n",
        "\n",
        "# Resolve directories robustly\n",
        "try:\n",
        "    THIS_DIR = os.path.dirname(os.path.abspath(__file__))  # type: ignore[name-defined]\n",
        "except NameError:\n",
        "    THIS_DIR = os.getcwd()\n",
        "DATA_DIR = os.path.join(os.path.dirname(THIS_DIR), \"data\")\n",
        "NOTEBOOK_NAME = \"Jajiga.ipynb\"\n",
        "SUBMISSION_NAME = \"submission.csv\"\n",
        "RESULT_ZIP = \"result.zip\"\n",
        "\n",
        "try:\n",
        "    from catboost import CatBoostRegressor, Pool  # type: ignore\n",
        "except Exception:\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"uv\", \"pip\", \"install\", \"-q\", \"catboost\"])  # uses uv per preference\n",
        "    except Exception:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"catboost\"])\n",
        "    from catboost import CatBoostRegressor, Pool  # type: ignore\n",
        "\n",
        "train_path = os.path.join(DATA_DIR, \"train.csv\")\n",
        "test_path = os.path.join(DATA_DIR, \"test.csv\")\n",
        "\n",
        "\n",
        "def parse_tags(value: object) -> str:\n",
        "    if isinstance(value, list):\n",
        "        items = value\n",
        "    elif isinstance(value, str):\n",
        "        try:\n",
        "            items = ast.literal_eval(value)\n",
        "        except Exception:\n",
        "            items = [value]\n",
        "    else:\n",
        "        items = []\n",
        "    tags: List[str] = []\n",
        "    for item in items:\n",
        "        if isinstance(item, dict):\n",
        "            name = item.get(\"name\")\n",
        "            if name is not None:\n",
        "                tags.append(str(name))\n",
        "        else:\n",
        "            tags.append(str(item))\n",
        "    tags = [t.strip() for t in tags if t and t != \"None\"]\n",
        "    return \" \".join(sorted(set(tags)))\n",
        "\n",
        "\n",
        "def parse_sleep_arrange(value: object) -> Dict[str, int]:\n",
        "    counts: Dict[str, int] = {\"sleep_single\": 0, \"sleep_double\": 0, \"sleep_mattress\": 0}\n",
        "    items: List[object]\n",
        "    if isinstance(value, str):\n",
        "        try:\n",
        "            items = ast.literal_eval(value)\n",
        "        except Exception:\n",
        "            items = []\n",
        "    elif isinstance(value, list):\n",
        "        items = value\n",
        "    else:\n",
        "        items = []\n",
        "    for entry in items:\n",
        "        if isinstance(entry, dict):\n",
        "            counts[\"sleep_single\"] += int(entry.get(\"single\") or 0)\n",
        "            counts[\"sleep_double\"] += int(entry.get(\"double\") or 0)\n",
        "            counts[\"sleep_mattress\"] += int(entry.get(\"mattress\") or 0)\n",
        "    counts[\"sleep_total\"] = counts[\"sleep_single\"] + counts[\"sleep_double\"] + counts[\"sleep_mattress\"]\n",
        "    return counts\n",
        "\n",
        "\n",
        "def prepare_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "\n",
        "    # Convert tag-like fields to space-separated tokens\n",
        "    for col, new_col in [\n",
        "        (\"types\", \"types_text\"),\n",
        "        (\"regions\", \"regions_text\"),\n",
        "        (\"features\", \"features_text\"),\n",
        "        (\"rules\", \"rules_text\"),\n",
        "    ]:\n",
        "        if col in out.columns:\n",
        "            out[new_col] = out[col].apply(parse_tags)\n",
        "        else:\n",
        "            out[new_col] = \"\"\n",
        "\n",
        "    # Sleep arrangement derived counts\n",
        "    if \"sleep_arrange\" in out.columns:\n",
        "        sleep_counts = out[\"sleep_arrange\"].apply(parse_sleep_arrange).apply(pd.Series)\n",
        "        out = pd.concat([out, sleep_counts], axis=1)\n",
        "\n",
        "    # Coerce numeric-likes\n",
        "    numeric_like = [\n",
        "        \"floor_area\",\n",
        "        \"land_area\",\n",
        "        \"floors_count\",\n",
        "        \"bedrooms\",\n",
        "        \"guest_number\",\n",
        "        \"max_guest_number\",\n",
        "        \"stays_min\",\n",
        "        \"stays_max\",\n",
        "        \"entrance_time_min\",\n",
        "        \"entrance_time_max\",\n",
        "        \"leaving_time\",\n",
        "        \"ratings.count\",\n",
        "        \"ratings.total\",\n",
        "        \"ratings.cleanliness\",\n",
        "        \"ratings.location\",\n",
        "        \"ratings.checkin\",\n",
        "        \"ratings.value\",\n",
        "        \"units_count\",\n",
        "        \"success_books\",\n",
        "        \"geo.lat\",\n",
        "        \"geo.lng\",\n",
        "        \"sleep_single\",\n",
        "        \"sleep_double\",\n",
        "        \"sleep_mattress\",\n",
        "        \"sleep_total\",\n",
        "    ]\n",
        "    for c in numeric_like:\n",
        "        if c in out.columns:\n",
        "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
        "\n",
        "    # Derived features\n",
        "    if set([\"floor_area\", \"bedrooms\"]).issubset(out.columns):\n",
        "        out[\"area_per_bedroom\"] = out[\"floor_area\"] / out[\"bedrooms\"].replace(0, np.nan)\n",
        "    if set([\"guest_number\", \"bedrooms\"]).issubset(out.columns):\n",
        "        out[\"guests_per_bedroom\"] = out[\"guest_number\"] / out[\"bedrooms\"].replace(0, np.nan)\n",
        "    if set([\"max_guest_number\", \"guest_number\"]).issubset(out.columns):\n",
        "        out[\"extra_guest_capacity\"] = out[\"max_guest_number\"] - out[\"guest_number\"]\n",
        "    if set([\"ratings.total\", \"ratings.count\"]).issubset(out.columns):\n",
        "        out[\"avg_rating\"] = out[\"ratings.total\"] / out[\"ratings.count\"].replace(0, np.nan)\n",
        "\n",
        "    # Text lengths and word counts\n",
        "    for tcol in [\"title\", \"description\", \"sleep_description\"]:\n",
        "        if tcol in out.columns:\n",
        "            s = out[tcol].fillna(\"\").astype(str)\n",
        "            out[f\"len_{tcol}\"] = s.str.len()\n",
        "            out[f\"wc_{tcol}\"] = s.str.split().map(len)\n",
        "\n",
        "    # Ensure text/string columns are strings\n",
        "    for c in [\n",
        "        \"title\",\n",
        "        \"description\",\n",
        "        \"sleep_description\",\n",
        "        \"types_text\",\n",
        "        \"regions_text\",\n",
        "        \"features_text\",\n",
        "        \"rules_text\",\n",
        "    ]:\n",
        "        if c in out.columns:\n",
        "            out[c] = out[c].fillna(\"\").astype(str)\n",
        "        else:\n",
        "            out[c] = \"\"\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# Load\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "train_feat = prepare_df(train_df)\n",
        "test_feat = prepare_df(test_df)\n",
        "\n",
        "TARGET = \"min_price\"\n",
        "y = train_feat[TARGET].to_numpy()\n",
        "X = train_feat.drop(columns=[TARGET])\n",
        "\n",
        "# Column groups\n",
        "base_numeric = [\n",
        "    \"floor_area\",\"land_area\",\"floors_count\",\"bedrooms\",\"guest_number\",\"max_guest_number\",\n",
        "    \"stays_min\",\"stays_max\",\"entrance_time_min\",\"entrance_time_max\",\"leaving_time\",\n",
        "    \"ratings.count\",\"ratings.total\",\"ratings.cleanliness\",\"ratings.location\",\"ratings.checkin\",\"ratings.value\",\n",
        "    \"units_count\",\"success_books\",\"geo.lat\",\"geo.lng\",\"sleep_single\",\"sleep_double\",\"sleep_mattress\",\"sleep_total\",\n",
        "    \"area_per_bedroom\",\"guests_per_bedroom\",\"extra_guest_capacity\",\"avg_rating\",\n",
        "    \"len_title\",\"wc_title\",\"len_description\",\"wc_description\",\"len_sleep_description\",\"wc_sleep_description\",\n",
        "]\n",
        "numeric_cols = [c for c in base_numeric if c in X.columns]\n",
        "\n",
        "categorical_cols = [\n",
        "    c for c in [\n",
        "        \"status\",\"allocation\",\"province.id\",\"province.name\",\"city.id\",\"city.name\",\n",
        "        \"province.url\",\"city.url\",\"is_clean\",\"is_new\",\"is_instant\",\"is_plus\",\n",
        "    ] if c in X.columns\n",
        "]\n",
        "\n",
        "text_cols_all = [\n",
        "    c for c in [\n",
        "        \"title\",\"description\",\"sleep_description\",\"types_text\",\"regions_text\",\"features_text\",\"rules_text\",\n",
        "    ] if c in X.columns\n",
        "]\n",
        "text_cols = ([] if FAST_MODE else text_cols_all)\n",
        "\n",
        "selected_cols = [c for c in (numeric_cols + categorical_cols + text_cols) if c in X.columns]\n",
        "\n",
        "# Prepare data types for CatBoost\n",
        "X_cb = X[selected_cols].copy()\n",
        "for c in categorical_cols + text_cols:\n",
        "    if c in X_cb.columns:\n",
        "        X_cb[c] = X_cb[c].astype(str).fillna(\"\")\n",
        "for c in numeric_cols:\n",
        "    if c in X_cb.columns:\n",
        "        X_cb[c] = pd.to_numeric(X_cb[c], errors=\"coerce\")\n",
        "\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(X_cb, y, test_size=0.2, random_state=RANDOM_STATE, shuffle=True)\n",
        "\n",
        "cat_idx = [X_cb.columns.get_loc(c) for c in categorical_cols if c in X_cb.columns]\n",
        "text_idx = [X_cb.columns.get_loc(c) for c in text_cols if c in X_cb.columns]\n",
        "\n",
        "# Train with log-target for stability\n",
        "y_tr_log = np.log1p(y_tr)\n",
        "y_va_log = np.log1p(y_va)\n",
        "\n",
        "from catboost import CatBoostRegressor, Pool  # type: ignore  # after potential install\n",
        "train_pool = Pool(X_tr, y_tr_log, cat_features=cat_idx, text_features=text_idx)\n",
        "valid_pool = Pool(X_va, y_va_log, cat_features=cat_idx, text_features=text_idx)\n",
        "\n",
        "model = CatBoostRegressor(\n",
        "    iterations=(20000 if FAST_MODE else 50000),\n",
        "    learning_rate=(0.04 if FAST_MODE else 0.035),\n",
        "    depth=(30 if FAST_MODE else 50),\n",
        "    l2_leaf_reg=(8.0 if FAST_MODE else 10.0),\n",
        "    loss_function=\"RMSE\",\n",
        "    eval_metric=\"R2\",\n",
        "    subsample=0.85,\n",
        "    rsm=(0.7 if FAST_MODE else 0.6),\n",
        "    random_seed=RANDOM_STATE,\n",
        "    allow_writing_files=False,\n",
        "    od_type=\"Iter\",\n",
        "    od_wait=(700 if FAST_MODE else 900),\n",
        "    verbose=200,\n",
        "    thread_count=MAX_THREADS,\n",
        ")\n",
        "\n",
        "model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
        "\n",
        "pred_va = np.expm1(model.predict(valid_pool))\n",
        "r2 = r2_score(y_va, pred_va)\n",
        "print(f\"Validation R2: {r2:.4f}  -> approx score {round(r2,3)*250:.1f}\")\n",
        "\n",
        "best_it = getattr(model, \"best_iteration_\", None)\n",
        "if best_it is None:\n",
        "    best_it = model.tree_count_\n",
        "\n",
        "# Fit final on full data with best iterations\n",
        "X_full = X_cb.copy()\n",
        "for c in categorical_cols + text_cols:\n",
        "    if c in X_full.columns:\n",
        "        X_full[c] = X_full[c].astype(str).fillna(\"\")\n",
        "for c in numeric_cols:\n",
        "    if c in X_full.columns:\n",
        "        X_full[c] = pd.to_numeric(X_full[c], errors=\"coerce\")\n",
        "\n",
        "full_pool = Pool(X_full, np.log1p(y), cat_features=cat_idx, text_features=text_idx)\n",
        "final_model = CatBoostRegressor(\n",
        "    iterations=int(best_it),\n",
        "    learning_rate=(0.06 if FAST_MODE else 0.035),\n",
        "    depth=(6 if FAST_MODE else 8),\n",
        "    l2_leaf_reg=(4.0 if FAST_MODE else 6.0),\n",
        "    loss_function=\"RMSE\",\n",
        "    subsample=0.85,\n",
        "    rsm=(0.95 if FAST_MODE else 0.9),\n",
        "    random_seed=RANDOM_STATE,\n",
        "    allow_writing_files=False,\n",
        "    verbose=False,\n",
        "    thread_count=MAX_THREADS,\n",
        ")\n",
        "final_model.fit(full_pool)\n",
        "\n",
        "# Predict test\n",
        "X_test = test_feat[selected_cols].copy()\n",
        "for c in categorical_cols + text_cols:\n",
        "    if c in X_test.columns:\n",
        "        X_test[c] = X_test[c].astype(str).fillna(\"\")\n",
        "for c in numeric_cols:\n",
        "    if c in X_test.columns:\n",
        "        X_test[c] = pd.to_numeric(X_test[c], errors=\"coerce\")\n",
        "\n",
        "test_pool = Pool(X_test, cat_features=cat_idx, text_features=text_idx)\n",
        "pred_test = np.expm1(final_model.predict(test_pool))\n",
        "pred_test = np.maximum(pred_test, 0)\n",
        "\n",
        "# Save outputs\n",
        "submission_path = os.path.join(THIS_DIR, SUBMISSION_NAME)\n",
        "submission = pd.DataFrame({\"min_price\": pred_test})\n",
        "submission.to_csv(submission_path, index=False)\n",
        "print(f\"Saved submission to {submission_path}\")\n",
        "\n",
        "# Zip\n",
        "result_zip_path = os.path.join(THIS_DIR, RESULT_ZIP)\n",
        "with zipfile.ZipFile(result_zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    zf.write(submission_path, SUBMISSION_NAME)\n",
        "    nb_path = os.path.join(THIS_DIR, NOTEBOOK_NAME)\n",
        "    if os.path.exists(nb_path):\n",
        "        zf.write(nb_path, NOTEBOOK_NAME)\n",
        "print(f\"Wrote {result_zip_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
