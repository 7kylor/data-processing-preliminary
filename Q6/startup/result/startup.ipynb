{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "    Startup\n",
    "</font>\n",
    "</h1>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    In this question, we aim to design a model that can predict whether a startup will succeed or not.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Introduction to the Dataset\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The initial file for this question contains two files named <code>train.csv</code> and <code>test.csv</code>, which are the training and test datasets, respectively.\n",
    "    <br>\n",
    "    The training dataset has 57615 rows and 12 columns (features), whose descriptions are provided in the table below.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div align=center style=\"line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "\n",
    "|      <b>Feature Name</b>       |                          <b>Feature Description</b>                           |\n",
    "| :----------------------------: | :---------------------------------------------------------------------------: |\n",
    "|       <code>name</code>        |                                 Company Name                                  |\n",
    "|   <code>category_list</code>   |                           Company Business Category                           |\n",
    "| <code>funding_total_usd</code> |                            Total Funding (in USD)                             |\n",
    "|      <code>status</code>       | Company Status (The target variable, which you need to modify slightly later) |\n",
    "|   <code>country_code</code>    |                                 Country Code                                  |\n",
    "|    <code>state_code</code>     |                                  State Code                                   |\n",
    "|      <code>region</code>       |                                    Region                                     |\n",
    "|       <code>city</code>        |                                     City                                      |\n",
    "|  <code>funding_rounds</code>   |                           Number of Funding Rounds                            |\n",
    "|    <code>founded_at</code>     |                                 Date Founded                                  |\n",
    "| <code>first_funding_at</code>  |                             Date of First Funding                             |\n",
    "|  <code>last_funding_at</code>  |                             Date of Last Funding                              |\n",
    "\n",
    "</font>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The test dataset also has 8752 rows and its columns are similar to the training dataset, except that it does not have the <code>status</code> column.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Reading the Dataset\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Initially, you need to import your required libraries. Then, based on the descriptions above, read the training and test datasets appropriately and perform the necessary preprocessing on them.\n",
    "    <br>\n",
    "    If you look closely at the data, the values in the <code>status</code> column are <code>operating</code>, <code>closed</code>, <code>acquired</code>, and <code>ipo</code>. \n",
    "    We consider a company successful if it is in one of the two statuses: <code>acquired</code> or <code>ipo</code>. The <code>closed</code> status means the startup has failed and the company is shut down, and the <code>operating</code> status means the company has not yet achieved success but has not gone bankrupt yet.\n",
    "     Therefore, your model should ultimately output one of three numbers as a prediction: 0 (Failed and shut down), 1 (Not successful but not shut down), and 2 (Successful).\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (57616, 12) Test shape: (8752, 11)\n",
      "Dropped rows with unknown status: 0\n"
     ]
    }
   ],
   "source": [
    "# Reading/Loading the dataset files\n",
    "train_path = os.path.join(os.getcwd(), 'train.csv')\n",
    "test_path = os.path.join(os.getcwd(), 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Parse dates and coerce numerics\n",
    "date_cols = ['founded_at', 'first_funding_at', 'last_funding_at']\n",
    "for c in date_cols:\n",
    "    train_df[c] = pd.to_datetime(train_df[c], errors='coerce')\n",
    "    test_df[c] = pd.to_datetime(test_df[c], errors='coerce')\n",
    "\n",
    "for c in ['funding_total_usd', 'funding_rounds']:\n",
    "    train_df[c] = pd.to_numeric(train_df[c], errors='coerce')\n",
    "    test_df[c] = pd.to_numeric(test_df[c], errors='coerce')\n",
    "\n",
    "# Map target variable: closed→0, operating→1, acquired/ipo→2\n",
    "def map_status_to_target(s):\n",
    "    if s == 'closed':\n",
    "        return 0\n",
    "    if s == 'operating':\n",
    "        return 1\n",
    "    if s in ('acquired', 'ipo'):\n",
    "        return 2\n",
    "    return np.nan\n",
    "\n",
    "y = train_df['status'].map(map_status_to_target).astype('float').astype('Int64')\n",
    "\n",
    "# Keep a copy of features\n",
    "X_full = train_df.drop(columns=['status']).copy()\n",
    "X_test_full = test_df.copy()\n",
    "\n",
    "# Drop any rows with unknown target labels\n",
    "idx = y.notna()\n",
    "X_full = X_full.loc[idx].copy()\n",
    "y = y.loc[idx].astype(int)\n",
    "\n",
    "print('Train shape:', train_df.shape, 'Test shape:', test_df.shape)\n",
    "print('Dropped rows with unknown status:', int((~idx).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing step\n",
    "def prepare_features(df, city_keep=None, state_keep=None, is_train=False):\n",
    "    out = df.copy()\n",
    "\n",
    "    # Main category from category_list\n",
    "    out['category_main'] = out['category_list'].astype(str).str.split('|').str[0].str.strip()\n",
    "    out.loc[out['category_main'].isna() | (out['category_main'] == '') | (out['category_main'].str.lower() == 'nan'), 'category_main'] = 'Unknown'\n",
    "\n",
    "    # Simple text length feature\n",
    "    out['name_len'] = out['name'].astype(str).str.len()\n",
    "\n",
    "    # Category count\n",
    "    cat_series = out['category_list'].astype(str)\n",
    "    valid_cat = (cat_series.str.lower() != 'nan') & (cat_series.str.strip() != '')\n",
    "    out['category_count'] = 0\n",
    "    out.loc[valid_cat, 'category_count'] = cat_series[valid_cat].str.count('\\|') + 1\n",
    "\n",
    "    # Date-derived features\n",
    "    out['days_to_first_funding'] = (out['first_funding_at'] - out['founded_at']).dt.days\n",
    "    out['days_funding_span'] = (out['last_funding_at'] - out['first_funding_at']).dt.days\n",
    "    out['age_at_last_funding'] = (out['last_funding_at'] - out['founded_at']).dt.days\n",
    "\n",
    "    out['founded_year'] = out['founded_at'].dt.year\n",
    "    out['first_funding_year'] = out['first_funding_at'].dt.year\n",
    "    out['last_funding_year'] = out['last_funding_at'].dt.year\n",
    "\n",
    "    out['founded_month'] = out['founded_at'].dt.month\n",
    "    out['first_funding_month'] = out['first_funding_at'].dt.month\n",
    "    out['last_funding_month'] = out['last_funding_at'].dt.month\n",
    "\n",
    "    # Log transform funding and simple indicator\n",
    "    out['log_funding_total_usd'] = np.log1p(out['funding_total_usd'])\n",
    "    out['has_funding'] = (out['funding_rounds'] > 0).astype(int)\n",
    "\n",
    "    # Reduce high-cardinality city and state_code using frequency thresholds\n",
    "    if is_train:\n",
    "        city_counts = out['city'].astype(str).value_counts()\n",
    "        city_keep = set(city_counts[city_counts >= 50].index)\n",
    "        state_counts = out['state_code'].astype(str).value_counts()\n",
    "        state_keep = set(state_counts[state_counts >= 100].index)\n",
    "\n",
    "    out['city_reduced'] = out['city'].astype(str).where(out['city'].astype(str).isin(city_keep), other='Other')\n",
    "    out['state_code_reduced'] = out['state_code'].astype(str).where(out['state_code'].astype(str).isin(state_keep), other='Other')\n",
    "\n",
    "    if is_train:\n",
    "        return out, city_keep, state_keep\n",
    "    return out\n",
    "\n",
    "# Prepare train and test feature DataFrames\n",
    "X_prepared, city_keep_set, state_keep_set = prepare_features(X_full, is_train=True)\n",
    "X_test_prepared = prepare_features(X_test_full, city_keep=city_keep_set, state_keep=state_keep_set, is_train=False)\n",
    "\n",
    "# Define feature lists\n",
    "numeric_features = [\n",
    "    'funding_total_usd', 'funding_rounds', 'log_funding_total_usd',\n",
    "    'days_to_first_funding', 'days_funding_span', 'age_at_last_funding',\n",
    "    'founded_year', 'first_funding_year', 'last_funding_year',\n",
    "    'founded_month', 'first_funding_month', 'last_funding_month',\n",
    "    'category_count', 'has_funding', 'name_len'\n",
    "]\n",
    "categorical_features = ['country_code', 'state_code_reduced', 'region', 'city_reduced', 'category_main']\n",
    "\n",
    "feature_cols = numeric_features + categorical_features\n",
    "\n",
    "# Final X matrices\n",
    "X = X_prepared[feature_cols].copy()\n",
    "X_test_final = X_test_prepared[feature_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Model Training\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Now that you have cleaned the data, it's time to train a model that can predict the target variable of this problem.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logreg macro F1: 0.4996\n",
      "Model linsvc macro F1: 0.5130\n",
      "Model rf macro F1: 0.5248\n",
      "Model hgb macro F1: 0.4722\n",
      "Selected best model: rf with macro F1 = 0.5248\n"
     ]
    }
   ],
   "source": [
    "# Model design\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessors\n",
    "numeric_transformer_lr = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_ohe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_lr, numeric_features),\n",
    "        ('cat', categorical_transformer_ohe, categorical_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "numeric_transformer_tree = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer_ord = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocessor_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_tree, numeric_features),\n",
    "        ('cat', categorical_transformer_ord, categorical_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Candidate models\n",
    "models = {\n",
    "    'logreg': Pipeline(steps=[('preprocessor', preprocessor_lr),\n",
    "                              ('clf', LogisticRegression(solver='saga', penalty='l2', max_iter=4000,\n",
    "                                                         class_weight='balanced', multi_class='ovr'))]),\n",
    "    'linsvc': Pipeline(steps=[('preprocessor', preprocessor_lr),\n",
    "                              ('clf', LinearSVC(C=1.0, class_weight='balanced'))]),\n",
    "    'rf': Pipeline(steps=[('preprocessor', preprocessor_tree),\n",
    "                          ('clf', RandomForestClassifier(n_estimators=500, max_depth=None,\n",
    "                                                         min_samples_leaf=2, n_jobs=-1,\n",
    "                                                         class_weight='balanced_subsample', random_state=42))]),\n",
    "    'hgb': Pipeline(steps=[('preprocessor', preprocessor_tree),\n",
    "                           ('clf', HistGradientBoostingClassifier(max_depth=8, learning_rate=0.1,\n",
    "                                                                 max_iter=500, random_state=42))])\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_score = -1.0\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_valid)\n",
    "    score = f1_score(y_valid, preds, average='macro')\n",
    "    scores[name] = score\n",
    "    print(f\"Model {name} macro F1: {score:.4f}\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = pipe\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"Selected best model: {best_model_name} with macro F1 = {best_score:.4f}\")\n",
    "\n",
    "# Use the best model for subsequent evaluation and submission\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Evaluation Metric\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The metric we have chosen for evaluating model performance is named <code>f1_score</code> (with the <code>macro</code> averaging method).\n",
    "    <br>\n",
    "    This metric is the measure for evaluating the quality of your model. In other words, the grading system also uses this same metric for scoring.\n",
    "    <br>\n",
    "    It is suggested that you evaluate your model's performance on the training or validation set based on this metric.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font color=\"red\"><b color='red'>Attention:</b></font>\n",
    "<font face=\"vazir\" size=3>\n",
    "    To receive a score for this question, your model's accuracy must be greater than the threshold of 0.4.\n",
    "    If your model's accuracy is less than 0.4, your score will be \n",
    "    <b>zero</b>\n",
    "    , otherwise, it will be calculated using the following formula:\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation macro F1 (best model): 0.5248\n"
     ]
    }
   ],
   "source": [
    "# evaluate your model\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, y_valid_pred, average='macro')\n",
    "print('Validation macro F1 (best model):', round(valid_f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " Prediction on Test Data and Output\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Save your model's predictions on the test data in a dataframe in the following format.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Note that the dataframe name must be <code>submission</code>; otherwise, the grading system will not be able to evaluate your output.\n",
    "    This dataframe only includes one column named <code>status</code> and has 8752 rows.\n",
    "    <br>\n",
    "    For each row in the test dataset, you must have a predicted value, which is your model's predicted <code>status</code> value.\n",
    "    For example, the table below shows the first 5 rows of the <code>submission</code> dataframe. These values are hypothetical and may be different in your answer.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div align=center \n",
    "style=\"direction: ltr;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "||<code>status</code>|\n",
    "|:----:|:-----:|\n",
    "|0|1|\n",
    "|1|2|\n",
    "|2|1|\n",
    "|3|1|\n",
    "|4|0|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test data and build submission\n",
    "# Retrain the selected best model on full data for final predictions\n",
    "# Rebuild best model using same selection process on full data\n",
    "\n",
    "# Fit all candidates on full data and pick best by internal CV-like split\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "candidates = {\n",
    "    'logreg': Pipeline(steps=[('preprocessor', preprocessor_lr),\n",
    "                              ('clf', LogisticRegression(solver='saga', penalty='l2', max_iter=4000,\n",
    "                                                         class_weight='balanced', multi_class='ovr'))]),\n",
    "    'linsvc': Pipeline(steps=[('preprocessor', preprocessor_lr),\n",
    "                              ('clf', LinearSVC(C=1.0, class_weight='balanced'))]),\n",
    "    'rf': Pipeline(steps=[('preprocessor', preprocessor_tree),\n",
    "                          ('clf', RandomForestClassifier(n_estimators=500, max_depth=None,\n",
    "                                                         min_samples_leaf=2, n_jobs=-1,\n",
    "                                                         class_weight='balanced_subsample', random_state=42))]),\n",
    "    'hgb': Pipeline(steps=[('preprocessor', preprocessor_tree),\n",
    "                           ('clf', HistGradientBoostingClassifier(max_depth=8, learning_rate=0.1,\n",
    "                                                                 max_iter=500, random_state=42))])\n",
    "}\n",
    "\n",
    "best_name, best_pipe, best_val = None, None, -1.0\n",
    "for name, pipe in candidates.items():\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    pred = pipe.predict(X_va)\n",
    "    sc = f1_score(y_va, pred, average='macro')\n",
    "    if sc > best_val:\n",
    "        best_name, best_pipe, best_val = name, pipe, sc\n",
    "print(f'Using {best_name} for final training (val macro F1 {best_val:.4f})')\n",
    "\n",
    "best_pipe.fit(X, y)\n",
    "\n",
    "y_test_pred = best_pipe.predict(X_test_final)\n",
    "submission = pd.DataFrame({'status': y_test_pred.astype(int)})\n",
    "print('Submission shape:', submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>Answer Builder Cell</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Run the cell below to create the <code>result.zip</code> file. Note that before running the cell below, you must have saved the changes made in the notebook (<code>ctrl+s</code>); otherwise, your score will be changed to zero at the end of the competition.\n",
    "    <br>\n",
    "    Also, if you are using Colab to run this notebook file, before submitting the <code>result.zip</code> file, download the latest version of your notebook and place it inside the submission file.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['startup.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'startup.ipynb')):\n",
    "    %notebook -e startup.ipynb\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "file_names = ['startup.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
