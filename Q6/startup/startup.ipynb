{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "    Startup\n",
    "</font>\n",
    "</h1>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    In this question, we aim to design a model that can predict whether a startup will succeed or not.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Introduction to the Dataset\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The initial file for this question contains two files named <code>train.csv</code> and <code>test.csv</code>, which are the training and test datasets, respectively.\n",
    "    <br>\n",
    "    The training dataset has 57615 rows and 12 columns (features), whose descriptions are provided in the table below.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div align=center style=\"line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "\n",
    "|      <b>Feature Name</b>       |                          <b>Feature Description</b>                           |\n",
    "| :----------------------------: | :---------------------------------------------------------------------------: |\n",
    "|       <code>name</code>        |                                 Company Name                                  |\n",
    "|   <code>category_list</code>   |                           Company Business Category                           |\n",
    "| <code>funding_total_usd</code> |                            Total Funding (in USD)                             |\n",
    "|      <code>status</code>       | Company Status (The target variable, which you need to modify slightly later) |\n",
    "|   <code>country_code</code>    |                                 Country Code                                  |\n",
    "|    <code>state_code</code>     |                                  State Code                                   |\n",
    "|      <code>region</code>       |                                    Region                                     |\n",
    "|       <code>city</code>        |                                     City                                      |\n",
    "|  <code>funding_rounds</code>   |                           Number of Funding Rounds                            |\n",
    "|    <code>founded_at</code>     |                                 Date Founded                                  |\n",
    "| <code>first_funding_at</code>  |                             Date of First Funding                             |\n",
    "|  <code>last_funding_at</code>  |                             Date of Last Funding                              |\n",
    "\n",
    "</font>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The test dataset also has 8752 rows and its columns are similar to the training dataset, except that it does not have the <code>status</code> column.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Reading the Dataset\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Initially, you need to import your required libraries. Then, based on the descriptions above, read the training and test datasets appropriately and perform the necessary preprocessing on them.\n",
    "    <br>\n",
    "    If you look closely at the data, the values in the <code>status</code> column are <code>operating</code>, <code>closed</code>, <code>acquired</code>, and <code>ipo</code>. \n",
    "    We consider a company successful if it is in one of the two statuses: <code>acquired</code> or <code>ipo</code>. The <code>closed</code> status means the startup has failed and the company is shut down, and the <code>operating</code> status means the company has not yet achieved success but has not gone bankrupt yet.\n",
    "     Therefore, your model should ultimately output one of three numbers as a prediction: 0 (Failed and shut down), 1 (Not successful but not shut down), and 2 (Successful).\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Evaluation Metric\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The metric we have chosen for evaluating model performance is named <code>f1_score</code> (with the <code>macro</code> averaging method).\n",
    "    <br>\n",
    "    This metric is the measure for evaluating the quality of your model. In other words, the grading system also uses this same metric for scoring.\n",
    "    <br>\n",
    "    It is suggested that you evaluate your model's performance on the training or validation set based on this metric.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font color=\"red\"><b color='red'>Attention:</b></font>\n",
    "<font face=\"vazir\" size=3>\n",
    "    To receive a score for this question, your model's accuracy must be greater than the threshold of 0.4.\n",
    "    If your model's accuracy is less than 0.4, your score will be \n",
    "    <b>zero</b>\n",
    "    , otherwise, it will be calculated using the following formula:\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " Prediction on Test Data and Output\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Save your model's predictions on the test data in a dataframe in the following format.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Note that the dataframe name must be <code>submission</code>; otherwise, the grading system will not be able to evaluate your output.\n",
    "    This dataframe only includes one column named <code>status</code> and has 8752 rows.\n",
    "    <br>\n",
    "    For each row in the test dataset, you must have a predicted value, which is your model's predicted <code>status</code> value.\n",
    "    For example, the table below shows the first 5 rows of the <code>submission</code> dataframe. These values are hypothetical and may be different in your answer.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div align=center \n",
    "style=\"direction: ltr;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "||<code>status</code>|\n",
    "|:----:|:-----:|\n",
    "|0|1|\n",
    "|1|2|\n",
    "|2|1|\n",
    "|3|1|\n",
    "|4|0|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>Answer Builder Cell</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Run the cell below to create the <code>result.zip</code> file. Note that before running the cell below, you must have saved the changes made in the notebook (<code>ctrl+s</code>); otherwise, your score will be changed to zero at the end of the competition.\n",
    "    <br>\n",
    "    Also, if you are using Colab to run this notebook file, before submitting the <code>result.zip</code> file, download the latest version of your notebook and place it inside the submission file.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Set, Dict\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (57616, 12) Test shape: (8752, 11)\n",
      "Dropped rows with unknown status: 0\n"
     ]
    }
   ],
   "source": [
    "# Reading/Loading the dataset files\n",
    "train_path = os.path.join(os.getcwd(), 'train.csv')\n",
    "test_path = os.path.join(os.getcwd(), 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Parse dates and coerce numerics\n",
    "date_cols = ['founded_at', 'first_funding_at', 'last_funding_at']\n",
    "for c in date_cols:\n",
    "    train_df[c] = pd.to_datetime(train_df[c], errors='coerce')\n",
    "    test_df[c] = pd.to_datetime(test_df[c], errors='coerce')\n",
    "\n",
    "for c in ['funding_total_usd', 'funding_rounds']:\n",
    "    train_df[c] = pd.to_numeric(train_df[c], errors='coerce')\n",
    "    test_df[c] = pd.to_numeric(test_df[c], errors='coerce')\n",
    "\n",
    "# Map target variable: closed→0, operating→1, acquired/ipo→2\n",
    "def map_status_to_target(s):\n",
    "    if s == 'closed':\n",
    "        return 0\n",
    "    if s == 'operating':\n",
    "        return 1\n",
    "    if s in ('acquired', 'ipo'):\n",
    "        return 2\n",
    "    return np.nan\n",
    "\n",
    "y = train_df['status'].map(map_status_to_target).astype('float').astype('Int64')\n",
    "\n",
    "# Keep a copy of features\n",
    "X_full = train_df.drop(columns=['status']).copy()\n",
    "X_test_full = test_df.copy()\n",
    "\n",
    "# Drop any rows with unknown target labels\n",
    "idx = y.notna()\n",
    "X_full = X_full.loc[idx].copy()\n",
    "y = y.loc[idx].astype(int)\n",
    "\n",
    "print('Train shape:', train_df.shape, 'Test shape:', test_df.shape)\n",
    "print('Dropped rows with unknown status:', int((~idx).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing step\n",
    "\n",
    "def prepare_features(\n",
    "    df: pd.DataFrame,\n",
    "    city_keep: Optional[Set[str]] = None,\n",
    "    state_keep: Optional[Set[str]] = None,\n",
    "    freq_maps: Optional[Dict[str, Dict[str, int]]] = None,\n",
    "    is_train: bool = False,\n",
    "):\n",
    "    out = df.copy()\n",
    "\n",
    "    # Main category from category_list\n",
    "    out['category_main'] = out['category_list'].astype(str).str.split('|').str[0].str.strip()\n",
    "    out.loc[\n",
    "        out['category_main'].isna()\n",
    "        | (out['category_main'] == '')\n",
    "        | (out['category_main'].str.lower() == 'nan'),\n",
    "        'category_main'\n",
    "    ] = 'Unknown'\n",
    "\n",
    "    # Name features\n",
    "    name_lc = out['name'].astype(str).str.lower()\n",
    "    out['name_len'] = out['name'].astype(str).str.len()\n",
    "    out['name_word_count'] = out['name'].astype(str).str.split().str.len()\n",
    "    out['name_has_inc'] = name_lc.str.contains(' inc').astype(int)\n",
    "    out['name_has_llc'] = name_lc.str.contains(' llc').astype(int)\n",
    "    out['name_has_labs'] = name_lc.str.contains(' labs').astype(int)\n",
    "    out['name_has_tech'] = name_lc.str.contains(' tech').astype(int)\n",
    "\n",
    "    # Category count and length\n",
    "    cat_series = out['category_list'].astype(str)\n",
    "    valid_cat = (cat_series.str.lower() != 'nan') & (cat_series.str.strip() != '')\n",
    "    out['category_count'] = 0\n",
    "    out.loc[valid_cat, 'category_count'] = cat_series[valid_cat].str.count('\\\\|') + 1\n",
    "    out['category_main_len'] = out['category_main'].astype(str).str.len()\n",
    "\n",
    "    # Date-derived features\n",
    "    out['days_to_first_funding'] = (out['first_funding_at'] - out['founded_at']).dt.days\n",
    "    out['days_funding_span'] = (out['last_funding_at'] - out['first_funding_at']).dt.days\n",
    "    out['age_at_last_funding'] = (out['last_funding_at'] - out['founded_at']).dt.days\n",
    "\n",
    "    # Clip negatives to zero\n",
    "    for c in ['days_to_first_funding', 'days_funding_span', 'age_at_last_funding']:\n",
    "        out[c] = out[c].clip(lower=0)\n",
    "\n",
    "    out['founded_year'] = out['founded_at'].dt.year\n",
    "    out['first_funding_year'] = out['first_funding_at'].dt.year\n",
    "    out['last_funding_year'] = out['last_funding_at'].dt.year\n",
    "\n",
    "    out['founded_month'] = out['founded_at'].dt.month\n",
    "    out['first_funding_month'] = out['first_funding_at'].dt.month\n",
    "    out['last_funding_month'] = out['last_funding_at'].dt.month\n",
    "\n",
    "    # Additional time features\n",
    "    out['activity_span_years'] = out['age_at_last_funding'] / 365.25\n",
    "    out['founded_decade'] = (out['founded_year'] // 10) * 10\n",
    "\n",
    "    # Funding transforms\n",
    "    out['log_funding_total_usd'] = np.log1p(out['funding_total_usd'])\n",
    "    out['has_funding'] = (out['funding_rounds'] > 0).astype(int)\n",
    "    denom = np.where(out['funding_rounds'].fillna(0).to_numpy() > 0, out['funding_rounds'].fillna(0).to_numpy(), 1)\n",
    "    out['funding_per_round'] = out['funding_total_usd'] / denom\n",
    "    out['log_funding_per_round'] = np.log1p(out['funding_per_round'])\n",
    "\n",
    "    # Reduce high-cardinality city and state_code using frequency thresholds\n",
    "    if is_train:\n",
    "        city_counts = out['city'].astype(str).value_counts()\n",
    "        city_keep = set(city_counts[city_counts >= 50].index)\n",
    "        state_counts = out['state_code'].astype(str).value_counts()\n",
    "        state_keep = set(state_counts[state_counts >= 100].index)\n",
    "\n",
    "    out['city_reduced'] = out['city'].astype(str).where(out['city'].astype(str).isin(city_keep), other='Other')\n",
    "    out['state_code_reduced'] = out['state_code'].astype(str).where(out['state_code'].astype(str).isin(state_keep), other='Other')\n",
    "\n",
    "    # Country flags\n",
    "    out['is_us'] = (out['country_code'].astype(str) == 'USA').astype(int)\n",
    "\n",
    "    # Frequency encodings learned on train, applied to both\n",
    "    keys = ['category_main', 'country_code', 'region', 'city_reduced', 'state_code_reduced']\n",
    "    if is_train:\n",
    "        freq_maps = {}\n",
    "        for k in keys:\n",
    "            freq_maps[k] = out[k].astype(str).value_counts().to_dict()\n",
    "\n",
    "    for k in keys:\n",
    "        fmap = freq_maps[k] if freq_maps is not None else {}\n",
    "        out[f'freq_{k}'] = out[k].astype(str).map(fmap).fillna(0).astype(int)\n",
    "\n",
    "    if is_train:\n",
    "        return out, city_keep, state_keep, freq_maps\n",
    "    return out\n",
    "\n",
    "# Prepare train and test feature DataFrames\n",
    "X_prepared, city_keep_set, state_keep_set, freq_maps_ = prepare_features(X_full, is_train=True)\n",
    "X_test_prepared = prepare_features(\n",
    "    X_test_full,\n",
    "    city_keep=city_keep_set,\n",
    "    state_keep=state_keep_set,\n",
    "    freq_maps=freq_maps_,\n",
    "    is_train=False,\n",
    ")\n",
    "\n",
    "# Define feature lists\n",
    "numeric_features = [\n",
    "    'funding_total_usd', 'funding_rounds', 'log_funding_total_usd',\n",
    "    'funding_per_round', 'log_funding_per_round',\n",
    "    'days_to_first_funding', 'days_funding_span', 'age_at_last_funding', 'activity_span_years',\n",
    "    'founded_year', 'first_funding_year', 'last_funding_year',\n",
    "    'founded_month', 'first_funding_month', 'last_funding_month', 'founded_decade',\n",
    "    'category_count', 'category_main_len',\n",
    "    'has_funding', 'is_us',\n",
    "    'name_len', 'name_word_count', 'name_has_inc', 'name_has_llc', 'name_has_labs', 'name_has_tech',\n",
    "    'freq_category_main', 'freq_country_code', 'freq_region', 'freq_city_reduced', 'freq_state_code_reduced',\n",
    "]\n",
    "\n",
    "categorical_features = ['country_code', 'state_code_reduced', 'region', 'city_reduced', 'category_main']\n",
    "\n",
    "feature_cols = numeric_features + categorical_features\n",
    "\n",
    "# Final X matrices\n",
    "X = X_prepared[feature_cols].copy()\n",
    "X_test_final = X_test_prepared[feature_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg CV macro F1: 0.4893 ± 0.0043\n",
      "linsvc CV macro F1: 0.5263 ± 0.0081\n",
      "rf CV macro F1: 0.4811 ± 0.0066\n",
      "et CV macro F1: 0.4942 ± 0.0048\n",
      "hgb CV macro F1: 0.4722 ± 0.0078\n",
      "stacking CV macro F1: 0.4986 ± 0.0088\n"
     ]
    }
   ],
   "source": [
    "# Model design with cross-validation and ensembling\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessors\n",
    "numeric_transformer_lr = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_ohe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_lr, numeric_features),\n",
    "        ('cat', categorical_transformer_ohe, categorical_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "numeric_transformer_tree = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer_ord = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocessor_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_tree, numeric_features),\n",
    "        ('cat', categorical_transformer_ord, categorical_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Candidate models\n",
    "logreg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_lr),\n",
    "    ('clf', LogisticRegression(solver='saga', penalty='l2', max_iter=6000,\n",
    "                              class_weight='balanced'))\n",
    "])\n",
    "\n",
    "linsvc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_lr),\n",
    "    ('clf', LinearSVC(C=0.8, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_tree),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=1200, max_depth=None, min_samples_leaf=1, min_samples_split=4, n_jobs=-1,\n",
    "        class_weight='balanced_subsample', random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "et = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_tree),\n",
    "    ('clf', ExtraTreesClassifier(\n",
    "        n_estimators=1500, max_depth=None, min_samples_leaf=1, min_samples_split=4, max_features=None, n_jobs=-1,\n",
    "        class_weight='balanced', random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "hgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_tree),\n",
    "    ('clf', HistGradientBoostingClassifier(max_depth=10, learning_rate=0.06,\n",
    "                                          max_iter=1200, random_state=42))\n",
    "])\n",
    "\n",
    "# Stacking and Voting (soft)\n",
    "estimators_for_stack = [\n",
    "    ('logreg', logreg),\n",
    "    ('rf', rf),\n",
    "    ('hgb', hgb),\n",
    "]\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=estimators_for_stack,\n",
    "    final_estimator=LogisticRegression(solver='lbfgs', max_iter=2000),\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_soft = VotingClassifier(\n",
    "    estimators=[('logreg', logreg), ('rf', rf), ('et', et), ('hgb', hgb)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'logreg': logreg,\n",
    "    'linsvc': linsvc,\n",
    "    'rf': rf,\n",
    "    'et': et,\n",
    "    'hgb': hgb,\n",
    "    'stacking': stacking,\n",
    "    'voting_soft': voting_soft,\n",
    "}\n",
    "\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores: Dict[str, float] = {}\n",
    "for name, pipe in models.items():\n",
    "    scores = cross_val_score(pipe, X_train, y_train, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "    cv_scores[name] = float(np.mean(scores))\n",
    "    print(f\"{name} CV macro F1: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n",
    "\n",
    "best_model_name = max(cv_scores.items(), key=lambda kv: kv[1])[0]\n",
    "model = models[best_model_name]\n",
    "\n",
    "# Fit best on the training split and evaluate on validation split\n",
    "model.fit(X_train, y_train)\n",
    "valid_pred = model.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, valid_pred, average='macro')\n",
    "print(f\"Selected best model: {best_model_name}; Holdout macro F1: {valid_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate your model\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, y_valid_pred, average='macro')\n",
    "print('Validation macro F1 (best model):', round(valid_f1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test data and build submission\n",
    "print(f'Using {best_model_name} for final training on full data')\n",
    "\n",
    "# Fit the selected model on the full training data\n",
    "model.fit(X, y)\n",
    "\n",
    "y_test_pred = model.predict(X_test_final)\n",
    "submission = pd.DataFrame({'status': y_test_pred.astype(int)})\n",
    "print('Submission:', submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'startup.ipynb')):\n",
    "    %notebook -e startup.ipynb\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "file_names = ['startup.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
