{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "    Startup\n",
    "</font>\n",
    "</h1>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    In this question, we aim to design a model that can predict whether a startup will succeed or not.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Introduction to the Dataset\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The initial file for this question contains two files named <code>train.csv</code> and <code>test.csv</code>, which are the training and test datasets, respectively.\n",
    "    <br>\n",
    "    The training dataset has 57615 rows and 12 columns (features), whose descriptions are provided in the table below.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div align=center style=\"line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "\n",
    "|      <b>Feature Name</b>       |                          <b>Feature Description</b>                           |\n",
    "| :----------------------------: | :---------------------------------------------------------------------------: |\n",
    "|       <code>name</code>        |                                 Company Name                                  |\n",
    "|   <code>category_list</code>   |                           Company Business Category                           |\n",
    "| <code>funding_total_usd</code> |                            Total Funding (in USD)                             |\n",
    "|      <code>status</code>       | Company Status (The target variable, which you need to modify slightly later) |\n",
    "|   <code>country_code</code>    |                                 Country Code                                  |\n",
    "|    <code>state_code</code>     |                                  State Code                                   |\n",
    "|      <code>region</code>       |                                    Region                                     |\n",
    "|       <code>city</code>        |                                     City                                      |\n",
    "|  <code>funding_rounds</code>   |                           Number of Funding Rounds                            |\n",
    "|    <code>founded_at</code>     |                                 Date Founded                                  |\n",
    "| <code>first_funding_at</code>  |                             Date of First Funding                             |\n",
    "|  <code>last_funding_at</code>  |                             Date of Last Funding                              |\n",
    "\n",
    "</font>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The test dataset also has 8752 rows and its columns are similar to the training dataset, except that it does not have the <code>status</code> column.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Reading the Dataset\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Initially, you need to import your required libraries. Then, based on the descriptions above, read the training and test datasets appropriately and perform the necessary preprocessing on them.\n",
    "    <br>\n",
    "    If you look closely at the data, the values in the <code>status</code> column are <code>operating</code>, <code>closed</code>, <code>acquired</code>, and <code>ipo</code>. \n",
    "    We consider a company successful if it is in one of the two statuses: <code>acquired</code> or <code>ipo</code>. The <code>closed</code> status means the startup has failed and the company is shut down, and the <code>operating</code> status means the company has not yet achieved success but has not gone bankrupt yet.\n",
    "     Therefore, your model should ultimately output one of three numbers as a prediction: 0 (Failed and shut down), 1 (Not successful but not shut down), and 2 (Successful).\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (57616, 12) Test shape: (8752, 11)\n",
      "Dropped rows with unknown status: 0\n"
     ]
    }
   ],
   "source": [
    "# Reading/Loading the dataset files\n",
    "train_path = os.path.join(os.getcwd(), 'train.csv')\n",
    "test_path = os.path.join(os.getcwd(), 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Parse dates and coerce numerics\n",
    "date_cols = ['founded_at', 'first_funding_at', 'last_funding_at']\n",
    "for c in date_cols:\n",
    "    train_df[c] = pd.to_datetime(train_df[c], errors='coerce')\n",
    "    test_df[c] = pd.to_datetime(test_df[c], errors='coerce')\n",
    "\n",
    "for c in ['funding_total_usd', 'funding_rounds']:\n",
    "    train_df[c] = pd.to_numeric(train_df[c], errors='coerce')\n",
    "    test_df[c] = pd.to_numeric(test_df[c], errors='coerce')\n",
    "\n",
    "# Map target variable: closed→0, operating→1, acquired/ipo→2\n",
    "def map_status_to_target(s):\n",
    "    if s == 'closed':\n",
    "        return 0\n",
    "    if s == 'operating':\n",
    "        return 1\n",
    "    if s in ('acquired', 'ipo'):\n",
    "        return 2\n",
    "    return np.nan\n",
    "\n",
    "y = train_df['status'].map(map_status_to_target).astype('float').astype('Int64')\n",
    "\n",
    "# Keep a copy of features\n",
    "X_full = train_df.drop(columns=['status']).copy()\n",
    "X_test_full = test_df.copy()\n",
    "\n",
    "# Drop any rows with unknown target labels\n",
    "idx = y.notna()\n",
    "X_full = X_full.loc[idx].copy()\n",
    "y = y.loc[idx].astype(int)\n",
    "\n",
    "print('Train shape:', train_df.shape, 'Test shape:', test_df.shape)\n",
    "print('Dropped rows with unknown status:', int((~idx).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing step\n",
    "def prepare_features(df, city_keep=None, state_keep=None, is_train=False):\n",
    "    out = df.copy()\n",
    "\n",
    "    # Main category from category_list\n",
    "    out['category_main'] = out['category_list'].astype(str).str.split('|').str[0].str.strip()\n",
    "    out.loc[out['category_main'].isna() | (out['category_main'] == '') | (out['category_main'].str.lower() == 'nan'), 'category_main'] = 'Unknown'\n",
    "\n",
    "    # Category count\n",
    "    cat_series = out['category_list'].astype(str)\n",
    "    valid_cat = (cat_series.str.lower() != 'nan') & (cat_series.str.strip() != '')\n",
    "    out['category_count'] = 0\n",
    "    out.loc[valid_cat, 'category_count'] = cat_series[valid_cat].str.count('\\|') + 1\n",
    "\n",
    "    # Date-derived features\n",
    "    out['days_to_first_funding'] = (out['first_funding_at'] - out['founded_at']).dt.days\n",
    "    out['days_funding_span'] = (out['last_funding_at'] - out['first_funding_at']).dt.days\n",
    "    out['age_at_last_funding'] = (out['last_funding_at'] - out['founded_at']).dt.days\n",
    "\n",
    "    out['founded_year'] = out['founded_at'].dt.year\n",
    "    out['first_funding_year'] = out['first_funding_at'].dt.year\n",
    "    out['last_funding_year'] = out['last_funding_at'].dt.year\n",
    "\n",
    "    out['founded_month'] = out['founded_at'].dt.month\n",
    "    out['first_funding_month'] = out['first_funding_at'].dt.month\n",
    "    out['last_funding_month'] = out['last_funding_at'].dt.month\n",
    "\n",
    "    # Log transform funding and simple indicator\n",
    "    out['log_funding_total_usd'] = np.log1p(out['funding_total_usd'])\n",
    "    out['has_funding'] = (out['funding_rounds'] > 0).astype(int)\n",
    "\n",
    "    # Reduce high-cardinality city and state_code using frequency thresholds\n",
    "    if is_train:\n",
    "        city_counts = out['city'].astype(str).value_counts()\n",
    "        city_keep = set(city_counts[city_counts >= 50].index)\n",
    "        state_counts = out['state_code'].astype(str).value_counts()\n",
    "        state_keep = set(state_counts[state_counts >= 100].index)\n",
    "\n",
    "    out['city_reduced'] = out['city'].astype(str).where(out['city'].astype(str).isin(city_keep), other='Other')\n",
    "    out['state_code_reduced'] = out['state_code'].astype(str).where(out['state_code'].astype(str).isin(state_keep), other='Other')\n",
    "\n",
    "    if is_train:\n",
    "        return out, city_keep, state_keep\n",
    "    return out\n",
    "\n",
    "# Prepare train and test feature DataFrames\n",
    "X_prepared, city_keep_set, state_keep_set = prepare_features(X_full, is_train=True)\n",
    "X_test_prepared = prepare_features(X_test_full, city_keep=city_keep_set, state_keep=state_keep_set, is_train=False)\n",
    "\n",
    "# Define feature lists\n",
    "numeric_features = [\n",
    "    'funding_total_usd', 'funding_rounds', 'log_funding_total_usd',\n",
    "    'days_to_first_funding', 'days_funding_span', 'age_at_last_funding',\n",
    "    'founded_year', 'first_funding_year', 'last_funding_year',\n",
    "    'founded_month', 'first_funding_month', 'last_funding_month',\n",
    "    'category_count', 'has_funding'\n",
    "]\n",
    "categorical_features = ['country_code', 'state_code_reduced', 'region', 'city_reduced', 'category_main']\n",
    "\n",
    "feature_cols = numeric_features + categorical_features\n",
    "\n",
    "# Final X matrices\n",
    "X = X_prepared[feature_cols].copy()\n",
    "X_test_final = X_test_prepared[feature_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Model Training\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Now that you have cleaned the data, it's time to train a model that can predict the target variable of this problem.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HistGradientBoostingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 54\u001b[0m\n\u001b[1;32m     34\u001b[0m preprocessor_tree \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[1;32m     35\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     36\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, numeric_transformer_tree, numeric_features),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Candidate models\u001b[39;00m\n\u001b[1;32m     43\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogreg\u001b[39m\u001b[38;5;124m'\u001b[39m: Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor_lr),\n\u001b[1;32m     45\u001b[0m                               (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m, penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m,\n\u001b[1;32m     46\u001b[0m                                                          class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m))]),\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinsvc\u001b[39m\u001b[38;5;124m'\u001b[39m: Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor_lr),\n\u001b[1;32m     48\u001b[0m                               (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, LinearSVC(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m))]),\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m: Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor_tree),\n\u001b[1;32m     50\u001b[0m                           (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m                                                          min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     52\u001b[0m                                                          class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))]),\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhgb\u001b[39m\u001b[38;5;124m'\u001b[39m: Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor_tree),\n\u001b[0;32m---> 54\u001b[0m                            (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, HistGradientBoostingClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     55\u001b[0m                                                                  max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))])\n\u001b[1;32m     56\u001b[0m }\n\u001b[1;32m     58\u001b[0m scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     59\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HistGradientBoostingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Model design\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessors\n",
    "numeric_transformer_lr = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_ohe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_lr, numeric_features),\n",
    "        ('cat', categorical_transformer_ohe, categorical_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "numeric_transformer_tree = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer_ord = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocessor_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_tree, numeric_features),\n",
    "        ('cat', categorical_transformer_ord, categorical_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Candidate models\n",
    "models = {\n",
    "    'logreg': Pipeline(steps=[('preprocessor', preprocessor_lr),\n",
    "                              ('clf', LogisticRegression(solver='saga', penalty='l2', max_iter=4000,\n",
    "                                                         class_weight='balanced', multi_class='ovr'))]),\n",
    "    'linsvc': Pipeline(steps=[('preprocessor', preprocessor_lr),\n",
    "                              ('clf', LinearSVC(C=1.0, class_weight='balanced'))]),\n",
    "    'rf': Pipeline(steps=[('preprocessor', preprocessor_tree),\n",
    "                          ('clf', RandomForestClassifier(n_estimators=500, max_depth=None,\n",
    "                                                         min_samples_leaf=2, n_jobs=-1,\n",
    "                                                         class_weight='balanced_subsample', random_state=42))]),\n",
    "    'hgb': Pipeline(steps=[('preprocessor', preprocessor_tree),\n",
    "                           ('clf', HistGradientBoostingClassifier(max_depth=8, learning_rate=0.1,\n",
    "                                                                 max_iter=500, random_state=42))])\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_score = -1.0\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_valid)\n",
    "    score = f1_score(y_valid, preds, average='macro')\n",
    "    scores[name] = score\n",
    "    print(f\"Model {name} macro F1: {score:.4f}\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = pipe\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"Selected best model: {best_model_name} with macro F1 = {best_score:.4f}\")\n",
    "\n",
    "# Use the best model for subsequent evaluation and submission\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Evaluation Metric\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    The metric we have chosen for evaluating model performance is named <code>f1_score</code> (with the <code>macro</code> averaging method).\n",
    "    <br>\n",
    "    This metric is the measure for evaluating the quality of your model. In other words, the grading system also uses this same metric for scoring.\n",
    "    <br>\n",
    "    It is suggested that you evaluate your model's performance on the training or validation set based on this metric.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font color=\"red\"><b color='red'>Attention:</b></font>\n",
    "<font face=\"vazir\" size=3>\n",
    "    To receive a score for this question, your model's accuracy must be greater than the threshold of 0.4.\n",
    "    If your model's accuracy is less than 0.4, your score will be \n",
    "    <b>zero</b>\n",
    "    , otherwise, it will be calculated using the following formula:\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation macro F1: 0.0637\n"
     ]
    }
   ],
   "source": [
    "# evaluate your model\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, y_valid_pred, average='macro')\n",
    "print('Validation macro F1 (best model):', round(valid_f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " Prediction on Test Data and Output\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Save your model's predictions on the test data in a dataframe in the following format.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Note that the dataframe name must be <code>submission</code>; otherwise, the grading system will not be able to evaluate your output.\n",
    "    This dataframe only includes one column named <code>status</code> and has 8752 rows.\n",
    "    <br>\n",
    "    For each row in the test dataset, you must have a predicted value, which is your model's predicted <code>status</code> value.\n",
    "    For example, the table below shows the first 5 rows of the <code>submission</code> dataframe. These values are hypothetical and may be different in your answer.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div align=center \n",
    "style=\"direction: ltr;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "||<code>status</code>|\n",
    "|:----:|:-----:|\n",
    "|0|1|\n",
    "|1|2|\n",
    "|2|1|\n",
    "|3|1|\n",
    "|4|0|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (8752, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status\n",
       "0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions on test data and build submission\n",
    "# Retrain the selected best model on full data for final predictions\n",
    "# Rebuild best model using same selection process on full data\n",
    "\n",
    "# Fit all candidates on full data and pick best by internal CV-like split\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "candidates = {\n",
    "    'logreg': Pipeline(steps=[('preprocessor', preprocessor_lr),\n",
    "                              ('clf', LogisticRegression(solver='saga', penalty='l2', max_iter=4000,\n",
    "                                                         class_weight='balanced', multi_class='ovr'))]),\n",
    "    'linsvc': Pipeline(steps=[('preprocessor', preprocessor_lr),\n",
    "                              ('clf', LinearSVC(C=1.0, class_weight='balanced'))]),\n",
    "    'rf': Pipeline(steps=[('preprocessor', preprocessor_tree),\n",
    "                          ('clf', RandomForestClassifier(n_estimators=500, max_depth=None,\n",
    "                                                         min_samples_leaf=2, n_jobs=-1,\n",
    "                                                         class_weight='balanced_subsample', random_state=42))]),\n",
    "    'hgb': Pipeline(steps=[('preprocessor', preprocessor_tree),\n",
    "                           ('clf', HistGradientBoostingClassifier(max_depth=8, learning_rate=0.1,\n",
    "                                                                 max_iter=500, random_state=42))])\n",
    "}\n",
    "\n",
    "best_name, best_pipe, best_val = None, None, -1.0\n",
    "for name, pipe in candidates.items():\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    pred = pipe.predict(X_va)\n",
    "    sc = f1_score(y_va, pred, average='macro')\n",
    "    if sc > best_val:\n",
    "        best_name, best_pipe, best_val = name, pipe, sc\n",
    "print(f'Using {best_name} for final training (val macro F1 {best_val:.4f})')\n",
    "\n",
    "best_pipe.fit(X, y)\n",
    "\n",
    "y_test_pred = best_pipe.predict(X_test_final)\n",
    "submission = pd.DataFrame({'status': y_test_pred.astype(int)})\n",
    "print('Submission shape:', submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>Answer Builder Cell</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Run the cell below to create the <code>result.zip</code> file. Note that before running the cell below, you must have saved the changes made in the notebook (<code>ctrl+s</code>); otherwise, your score will be changed to zero at the end of the competition.\n",
    "    <br>\n",
    "    Also, if you are using Colab to run this notebook file, before submitting the <code>result.zip</code> file, download the latest version of your notebook and place it inside the submission file.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['startup.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'startup.ipynb')):\n",
    "    %notebook -e startup.ipynb\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "file_names = ['startup.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
