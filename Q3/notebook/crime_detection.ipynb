{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD9QagogiSdt"
   },
   "source": [
    "<h1 align=center style=\"line-height:200%;color:#0099cc\">\n",
    "<font color=\"#0099cc\">\n",
    "Criminology\n",
    "</font>\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFIZh7YuiSdw"
   },
   "source": [
    "<h2 align=left style=\"line-height:200%;color:#0099cc\">\n",
    "<font color=\"#0099cc\">\n",
    "Introduction and Problem Statement\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=ltr style=\"direction: ltr;text-align: justify;line-height:200%;font-size:medium\">\n",
    "<font size=3>\n",
    "Your goal in this problem is to create a predictive model that can classify new incidents into one of several crime categories using historical data. This model should help law enforcement agencies identify patterns of criminal behavior and make more informed decisions regarding crime prevention strategies in Los Angeles.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIK38OxIiSdx"
   },
   "source": [
    "<h2 align=left style=\"line-height:200%;color:#0099cc\">\n",
    "<font color=\"#0099cc\">\n",
    "Dataset Introduction\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=ltr style=\"direction: ltr; text-align: justify; line-height:200%; font-size:medium\">\n",
    "<font size=3>\n",
    "The training dataset contains 84,113 rows. The description of each column is provided in the table below.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=ltr style=\"direction: ltr;line-height:200%;font-size:medium\">\n",
    "<font size=3>\n",
    "    \n",
    "|Column|Description|\n",
    "|:------:|:---:|\n",
    "|DR_NO| A unique identifier for each crime report|\n",
    "|Date Rptd| Date the crime was reported|\n",
    "|DATE OCC| Date the crime occurred|\n",
    "|TIME OCC| Time the crime occurred|\n",
    "|AREA| Code of the area where the crime occurred|\n",
    "|AREA NAME| Name of the area where the crime occurred|\n",
    "|Rpt Dist No| Reporting District Number|\n",
    "|Crm Cd| Crime Code, indicating the crime category (This column is the target variable)|\n",
    "|Crm Cd Desc| Description of the crime|\n",
    "|Mocodes| Codes indicating the method used to commit the crime|\n",
    "|Vict Age| Victim's Age|\n",
    "|Vict Sex| Victim's Sex|\n",
    "|Vict Descent| Victim's Descent/Ethnicity|\n",
    "|Premis Cd| Code for the type of premises where the crime occurred|\n",
    "|Premis Desc| Description of the premises|\n",
    "|Weapon Used Cd| Code for the type of weapon used in the crime|\n",
    "|Weapon Desc| Description of the weapon used|\n",
    "|Status| Case Status (e.g., pending, closed)|\n",
    "|Status Desc| Description of the case status|\n",
    "|Crm Cd 1, Crm Cd 2, Crm Cd 3, Crm Cd 4| Additional crime codes if the incident involves multiple crimes|\n",
    "|LOCATION| Latitude and longitude of the crime|\n",
    "|Cross Street| Nearest cross street to the crime location|\n",
    "|LAT| Crime's latitude coordinate|\n",
    "|LON| Crime's longitude coordinate|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<p dir=ltr style=\"direction: ltr; text-align: justify; line-height:200%; font-size:medium\">\n",
    "<font size=3>\n",
    "The test dataset is similar to the training set, except that it does not contain the <code>Crm Cd</code> column, which is the target variable for the problem. It also does not contain the <code>Crm Cd 1</code>, <code>Crm Cd 2</code>, <code>Crm Cd 3</code>, <code>Crm Cd 4</code>, and <code>Crm Cd Desc</code> columns, which provide direct information about the target variable. The test dataset has 9346 rows and 21 columns.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPFvmd1QoKiL"
   },
   "source": [
    "<h3 align=left style=\"line-height:200%;color:#0099cc\">\n",
    "<font color=\"#0099cc\">\n",
    "Evaluation Metric\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=ltr style=\"direction: ltr; text-align: justify; line-height:200%; font-size:medium\">\n",
    "<font size=3>\n",
    "The evaluation metric used in the judging of this problem is the <code>F1 Macro</code> score, which examines precision and recall across all crime categories in a balanced manner. Unlike accuracy, which can be swayed by imbalanced data, the <code>F1 Macro</code> score calculates the <code>F1</code> score for each crime category independently and then computes their average. This metric ensures that performance on infrequent crime categories holds equal importance. This feature makes the metric suitable for predicting various types of crimes, regardless of their frequency in the dataset.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIfFWcc8qEAO"
   },
   "source": [
    "<h2 align=left style=\"line-height:200%;color:#0099cc\">\n",
    "<font color=\"#0099cc\">\n",
    "Prediction for Test Data and Output\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=ltr style=\"direction: ltr;text-align: left;line-height:200%;font-size:medium\">\n",
    "<font size=3>\n",
    "Use your model to predict the samples in the test data and prepare the results in a table format (<code>dataframe</code>) as shown below.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div dir=ltr style=\"direction: ltr;text-align: center;line-height:200%;font-size:medium\">\n",
    "<font size=3>\n",
    "    \n",
    "|Column|Description|\n",
    "|------|---|\n",
    "|Crm Cd|Predicted Crime Code|\n",
    "    \n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH8Y9d6JqmEf"
   },
   "source": [
    "<p dir=ltr style=\"direction: ltr;text-align: left;line-height:200%;font-size:medium\">\n",
    "<font size=3>\n",
    "The dataframe must be named <i>submission</i>; otherwise, the judging system cannot evaluate your effort.\n",
    "    <br>\n",
    "    This dataframe contains only 1 column named <i>Crm Cd</i> and has ? rows.\n",
    "    <br>\n",
    "    You must have one predicted value for each row in the <i>test</i> dataframe.\n",
    "    <br>\n",
    "    The table below shows the first 5 rows of the <code>submission</code> dataframe. Note that in your answer, the values of the <i>Crm Cd</i> column may be different.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align: center;line-height:200%;font-size:medium\">\n",
    "<font size=3>\n",
    "    \n",
    "|Crm Cd|\n",
    "|-----|\n",
    "|210|\n",
    "|420|\n",
    "|930|\n",
    "|624|\n",
    "|420|\n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# better to import these at the end of the file for performance\n",
    "# from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "# from sklearn.metrics import f1_score, make_scorer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (84113, 27)\n",
      "Test shape: (9346, 21)\n",
      "\n",
      "Top-10 missingness (train):\n",
      " Crm Cd 4          0.999964\n",
      "Crm Cd 3          0.998966\n",
      "Crm Cd 2          0.937168\n",
      "Cross Street      0.819243\n",
      "Weapon Desc       0.646654\n",
      "Weapon Used Cd    0.646654\n",
      "Mocodes           0.163411\n",
      "Vict Descent      0.160796\n",
      "Vict Sex          0.160784\n",
      "Premis Desc       0.000369\n",
      "dtype: float64\n",
      "\n",
      "Top-10 missingness (test):\n",
      " Cross Street      0.827841\n",
      "Weapon Desc       0.649155\n",
      "Weapon Used Cd    0.649155\n",
      "Mocodes           0.164883\n",
      "Vict Descent      0.162208\n",
      "Vict Sex          0.162208\n",
      "Premis Desc       0.000321\n",
      "LAT               0.000000\n",
      "LOCATION          0.000000\n",
      "Status Desc       0.000000\n",
      "dtype: float64\n",
      "\n",
      "Target distribution (top 15):\n",
      "Crm Cd\n",
      "510    11214\n",
      "624     8829\n",
      "330     6951\n",
      "740     6937\n",
      "310     6787\n",
      "230     6189\n",
      "440     5771\n",
      "626     5755\n",
      "420     5243\n",
      "354     5057\n",
      "210     3776\n",
      "745     3751\n",
      "341     2993\n",
      "331     2563\n",
      "930     2297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Quick EDA: shapes and missingness\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "# Basic missingness\n",
    "missing_train = train_df.isna().mean().sort_values(ascending=False).head(10)\n",
    "missing_test = test_df.isna().mean().sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop-10 missingness (train):\\n\", missing_train)\n",
    "print(\"\\nTop-10 missingness (test):\\n\", missing_test)\n",
    "\n",
    "# Target distribution (top 15 most frequent)\n",
    "if target_col in train_df.columns:\n",
    "    print(\"\\nTarget distribution (top 15):\")\n",
    "    print(train_df[target_col].value_counts().head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found: /Users/taher/Projects/data-processing–preliminary  /Q3/notebook/../data\n"
     ]
    }
   ],
   "source": [
    "# Locate data directory \n",
    "possible_data_dirs = [\n",
    "    os.path.join(os.getcwd(), 'data'),\n",
    "    os.path.join(os.getcwd(), '..', 'data'),\n",
    "    os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "]\n",
    "\n",
    "data_dir = None\n",
    "for p in possible_data_dirs:\n",
    "    if os.path.exists(os.path.join(p, 'train.csv')) and os.path.exists(os.path.join(p, 'test.csv')):\n",
    "        data_dir = p\n",
    "        print(f\"Data directory found: {data_dir}\")\n",
    "        break\n",
    "\n",
    "if data_dir is None:\n",
    "    raise FileNotFoundError(\"Could not find data directory containing train.csv and test.csv\")\n",
    "\n",
    "train_path = os.path.join(data_dir, 'train.csv')\n",
    "test_path = os.path.join(data_dir, 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "\n",
    "# define the target column\n",
    "target_col = 'Crm Cd'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (84113, 25)\n",
      "X_test shape: (9346, 25)\n",
      "\n",
      "Selected engineered feature summary (train):\n",
      "                  count         mean       std     min     25%     50%  \\\n",
      "TIME_OCC_HOUR   84113.0    13.423204  6.523232     0.0     9.0    14.0   \n",
      "Date Rptd_YEAR  84113.0  2020.055746  0.317548  2020.0  2020.0  2020.0   \n",
      "DATE OCC_YEAR   84113.0  2020.000000  0.000000  2020.0  2020.0  2020.0   \n",
      "\n",
      "                   75%     max  \n",
      "TIME_OCC_HOUR     19.0    23.0  \n",
      "Date Rptd_YEAR  2020.0  2024.0  \n",
      "DATE OCC_YEAR   2020.0  2020.0  \n",
      "\n",
      "First 5 feature columns:\n",
      "['TIME OCC', 'AREA', 'AREA NAME', 'Rpt Dist No', 'Vict Age']\n"
     ]
    }
   ],
   "source": [
    "# Feature matrix summary after encoding\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "# Numeric summary for a few key engineered columns if present\n",
    "cols_to_show = [c for c in ['TIME_OCC_HOUR','Date Rptd_YEAR','DATE OCC_YEAR'] if c in X_train.columns]\n",
    "if cols_to_show:\n",
    "    print(\"\\nSelected engineered feature summary (train):\")\n",
    "    print(X_train[cols_to_show].describe().T)\n",
    "\n",
    "print(\"\\nFirst 5 feature columns:\")\n",
    "print(list(X_train.columns[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are extracted and cleaned\n"
     ]
    }
   ],
   "source": [
    "# now lets define the function to build the features out of the training data\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_proc = df.copy()\n",
    "\n",
    "    # Extract time features\n",
    "    if 'TIME OCC' in df_proc.columns:\n",
    "        def extract_hour(val):\n",
    "            try:\n",
    "                t = int(val)\n",
    "            except Exception:\n",
    "                return np.nan\n",
    "            return (t // 100) % 24\n",
    "        df_proc['TIME_OCC_HOUR'] = df_proc['TIME OCC'].apply(extract_hour)\n",
    "\n",
    "    # Extract date features\n",
    "    for date_col in ['Date Rptd', 'DATE OCC']:\n",
    "        if date_col in df_proc.columns:\n",
    "            # infer the datetime format\n",
    "            dt = pd.to_datetime(\n",
    "                df_proc[date_col].astype(str).str.strip(),\n",
    "                format='%m/%d/%Y %I:%M:%S %p',\n",
    "                errors='coerce'\n",
    "            )\n",
    "            df_proc[date_col + '_YEAR'] = dt.dt.year\n",
    "            df_proc[date_col + '_MONTH'] = dt.dt.month\n",
    "            df_proc[date_col + '_DAY'] = dt.dt.day\n",
    "            df_proc[date_col + '_DOW'] = dt.dt.dayofweek\n",
    "\n",
    "    # Mocodes summary\n",
    "    if 'Mocodes' in df_proc.columns:\n",
    "        df_proc['MOCODES_COUNT'] = (\n",
    "            df_proc['Mocodes']\n",
    "            .fillna('')\n",
    "            .astype(str)\n",
    "            .map(lambda s: 0 if s.strip() == '' else len(s.strip().split()))\n",
    "        )\n",
    "\n",
    "    # Victim age cleaning\n",
    "    if 'Vict Age' in df_proc.columns:\n",
    "        df_proc['Vict Age'] = pd.to_numeric(df_proc['Vict Age'], errors='coerce')\n",
    "        df_proc['Vict Age'] = df_proc['Vict Age'].clip(lower=0, upper=100)\n",
    "\n",
    "    # Drop leakage / text-heavy columns not in test or too high-cardinality\n",
    "    drop_cols = [\n",
    "        'DR_NO', 'Crm Cd Desc', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4',\n",
    "        'Date Rptd', 'DATE OCC', 'Mocodes', 'LOCATION', 'Cross Street'\n",
    "    ]\n",
    "    df_proc = df_proc.drop(columns=[c for c in drop_cols if c in df_proc.columns], errors='ignore')\n",
    "\n",
    "    return df_proc\n",
    "\n",
    "print(\"Features are extracted and cleaned\")\n",
    "\n",
    "# print stats of the training data\n",
    "# print(train_df.describe())\n",
    "\n",
    "# print stats of the test data\n",
    "# print(test_df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train/Test Matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report (macro average emphasized):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         210      0.628     0.389     0.480      3776\n",
      "         230      0.692     0.794     0.739      6189\n",
      "         310      0.549     0.649     0.595      6787\n",
      "         330      0.478     0.738     0.580      6951\n",
      "         331      0.316     0.208     0.250      2563\n",
      "         341      0.278     0.077     0.121      2993\n",
      "         354      0.560     0.736     0.636      5057\n",
      "         420      0.333     0.073     0.119      5243\n",
      "         440      0.407     0.446     0.426      5771\n",
      "         510      0.829     0.986     0.901     11214\n",
      "         624      0.678     0.769     0.721      8829\n",
      "         626      0.657     0.714     0.685      5755\n",
      "         740      0.519     0.462     0.489      6937\n",
      "         745      0.275     0.095     0.141      3751\n",
      "         930      0.918     0.898     0.908      2297\n",
      "\n",
      "    accuracy                          0.605     84113\n",
      "   macro avg      0.541     0.535     0.519     84113\n",
      "weighted avg      0.572     0.605     0.573     84113\n",
      "\n",
      "\n",
      "Confusion matrix shape: (15, 15)\n",
      "Labels order: [210, 230, 310, 330, 331, 341, 354, 420, 440, 510] ...\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated diagnostics: classification report and confusion matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Use the same CV splitter\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "y_pred_cv = cross_val_predict(clf, X_train, y, cv=cv, n_jobs=-1)\n",
    "\n",
    "print(\"Classification report (macro average emphasized):\\n\")\n",
    "print(classification_report(y, y_pred_cv, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y, y_pred_cv, labels=np.unique(y))\n",
    "print(\"\\nConfusion matrix shape:\", cm.shape)\n",
    "print(\"Labels order:\", list(np.unique(y))[:10], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 84113 rows\n",
      "Test data has 9346 rows\n",
      "Combined data has 93459 rows\n"
     ]
    }
   ],
   "source": [
    "# Separate target\n",
    "y = train_df[target_col].astype(int)\n",
    "X_train_raw = train_df.drop(columns=[target_col], errors='ignore')\n",
    "X_test_raw = test_df.copy()\n",
    "\n",
    "# Build features\n",
    "X_train_feats = build_features(X_train_raw)\n",
    "X_test_feats = build_features(X_test_raw)\n",
    "\n",
    "# Combine to ensure consistent encoding of categoricals \n",
    "combined = pd.concat([X_train_feats, X_test_feats], axis=0, ignore_index=True)\n",
    "\n",
    "# Label-encode object columns deterministically\n",
    "object_cols = [c for c in combined.columns if combined[c].dtype == 'object']\n",
    "for col in object_cols:\n",
    "    combined[col] = combined[col].fillna('NA').astype('category').cat.codes.astype(np.int32)\n",
    "\n",
    "# Fill remaining numeric missing values\n",
    "for col in combined.columns:\n",
    "    if combined[col].dtype.kind in 'biufc':\n",
    "        combined[col] = combined[col].fillna(-1)\n",
    "\n",
    "# Split back\n",
    "X_train = combined.iloc[:len(X_train_feats), :].reset_index(drop=True)\n",
    "X_test = combined.iloc[len(X_train_feats):, :].reset_index(drop=True)\n",
    "\n",
    "# prient how many rows are in the training data and the test data and the combined data\n",
    "print(f\"Training data has {len(X_train)} rows\")\n",
    "print(f\"Test data has {len(X_test)} rows\")\n",
    "print(f\"Combined data has {len(combined)} rows\")\n",
    "\n",
    "# print the first 5 rows of the combined data for testing how the data looks like\n",
    "# print(combined.head())\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20 feature importances:\n",
      "\n",
      "Weapon Used Cd     0.101431\n",
      "Weapon Desc        0.089801\n",
      "MOCODES_COUNT      0.080005\n",
      "Premis Cd          0.072522\n",
      "Vict Age           0.057535\n",
      "LAT                0.052235\n",
      "LON                0.051947\n",
      "Premis Desc        0.048943\n",
      "Rpt Dist No        0.047628\n",
      "TIME OCC           0.046125\n",
      "DATE OCC_DAY       0.039181\n",
      "Date Rptd_DAY      0.038897\n",
      "TIME_OCC_HOUR      0.032744\n",
      "DATE OCC_MONTH     0.029500\n",
      "Date Rptd_MONTH    0.029377\n",
      "Vict Sex           0.028299\n",
      "Vict Descent       0.027430\n",
      "DATE OCC_DOW       0.026056\n",
      "Date Rptd_DOW      0.026052\n",
      "AREA NAME          0.023074\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature importance (top 20)\n",
    "# Fit once on full training for importances\n",
    "clf.fit(X_train, y)\n",
    "importances = getattr(clf, 'feature_importances_', None)\n",
    "if importances is not None:\n",
    "    fi = pd.Series(importances, index=X_train.columns).sort_values(ascending=False).head(20)\n",
    "    print(\"Top-20 feature importances:\\n\")\n",
    "    print(fi)\n",
    "else:\n",
    "    print(\"Model does not expose feature_importances_.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 400\n",
      "Depth of the trees: None\n",
      "Number of features considered for each split: sqrt\n",
      "Number of samples in each leaf: 2\n"
     ]
    }
   ],
   "source": [
    "# Train and predict phase yes\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# use RandomForestClassifier from sklearn\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ") \n",
    "\n",
    "# Print the model parameters the number of trees, the depth of the trees, the number of features considered for each split, and the number of samples in each leaf\n",
    "print(f\"Number of trees: {clf.n_estimators}\")\n",
    "print(f\"Depth of the trees: {clf.max_depth}\")\n",
    "print(f\"Number of features considered for each split: {clf.max_features}\")\n",
    "print(f\"Number of samples in each leaf: {clf.min_samples_leaf}\")\n",
    "\n",
    "\n",
    "# For test\n",
    "# print(clf)\n",
    "# Print the model summary\n",
    "# print(clf.get_params())\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "w36rHxW0qE6J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1-macro (3-fold): mean=0.519, std=0.001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optional - quick CV to gauge F1-macro\n",
    "try:\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    f1_scores = cross_val_score(\n",
    "        clf, X_train, y,\n",
    "        scoring='f1_macro',\n",
    "        cv=cv, n_jobs=-1\n",
    "    )\n",
    "    print(f\"CV F1-macro (3-fold): mean={f1_scores.mean():.3f}, std={f1_scores.std():.3f}\")\n",
    "except Exception as e:\n",
    "    print(f\"CV failed: {e}\")\n",
    "\n",
    "clf.fit(X_train, y)\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "\n",
    "submission = pd.DataFrame({'Crm Cd': pd.Series(y_pred).astype(int)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Builder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7PgaLKdiSdz"
   },
   "source": [
    "<h2 dir=ltr align=left style=\"line-height:200%;color:#0099cc\">\n",
    "<font color=\"#0099cc\">\n",
    "<b>Submission Builder Cell</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=ltr style=\"direction: ltr; text-align: justify; line-height:200%; font-size:medium\">\n",
    "<font size=3>\n",
    "Run the cell below to create the <code>result.zip</code> file. Note that before running the cell below, you must have saved the changes made in the notebook (<code>ctrl+s</code>); otherwise, your score will change to zero at the end of the competition.\n",
    "    <br>\n",
    "    Also, if you are using Colab to run this notebook file, download the latest version of your notebook and include it in the submission file before sending the <code>result.zip</code> file.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "T9jRlQwUiSdz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['crime_detection.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "file_names = ['crime_detection.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
