{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqrJsmuhLOAe"
   },
   "source": [
    "<h1 align=center style=\"line-height:200%;color:#0099cc\">\n",
    "    Movement Status\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W32EigaGpDmd"
   },
   "source": [
    "<h2 style=\"line-height:200%;color:#0099cc\">\n",
    "    Dataset Introduction\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-size:medium\">\n",
    "    The training dataset includes 270,688 rows, with the description of each column provided in the table below.\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div style=\"line-height:200%;font-size:medium\">\n",
    "|Column|Description|\n",
    "|:------:|:---:|\n",
    "|timestamp|Timestamp|\n",
    "|back_x|X-axis acceleration data from the lower back sensor|\n",
    "|back_y|Y-axis acceleration data from the lower back sensor|\n",
    "|back_z|Z-axis acceleration data from the lower back sensor|\n",
    "|thigh_x|X-axis acceleration data from the thigh sensor|\n",
    "|thigh_y|Y-axis acceleration data from the thigh sensor|\n",
    "|thigh_z|Z-axis acceleration data from the thigh sensor|\n",
    "|label|An integer representing the movement activity|\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-size:medium\">\n",
    "    The test dataset is similar to the training set, except it does not contain the <code>label</code> column, which is the target variable of the problem. The test dataset has 90,229 rows and 7 columns.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"line-height:200%;color:#0099cc\">\n",
    "    Reading the Dataset\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-size:medium\">\n",
    "    First, you need to import the necessary libraries. Then, based on the descriptions above, read the training and test datasets appropriately and perform the necessary preprocessing steps on them.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T17:21:37.706880Z",
     "iopub.status.busy": "2025-09-26T17:21:37.706750Z",
     "iopub.status.idle": "2025-09-26T17:22:42.932329Z",
     "shell.execute_reply": "2025-09-26T17:22:42.932061Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "\n",
    "# Modeling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utils\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T17:22:42.933753Z",
     "iopub.status.busy": "2025-09-26T17:22:42.933627Z",
     "iopub.status.idle": "2025-09-26T17:22:43.135084Z",
     "shell.execute_reply": "2025-09-26T17:22:43.134810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found: /Users/taher/Projects/data-processingâ€“preliminary  /Q4/notebook/../data\n",
      "                 timestamp    back_x    back_y    back_z   thigh_x   thigh_y  \\\n",
      "0  2000-01-01 00:00:00.000 -0.956569 -0.098830  0.080135 -0.960096 -0.162203   \n",
      "1  2000-01-01 00:00:00.020 -0.998093 -0.111525  0.078602 -1.020245 -0.092208   \n",
      "2  2000-01-01 00:00:00.040 -0.948218 -0.091371  0.083376 -0.970062 -0.115447   \n",
      "3  2000-01-01 00:00:00.060 -0.995374 -0.078641  0.099155 -1.011861 -0.133171   \n",
      "4  2000-01-01 00:00:00.080 -0.956965 -0.078572  0.088926 -0.999605 -0.024058   \n",
      "\n",
      "    thigh_z  label  \n",
      "0 -0.019368      6  \n",
      "1 -0.045086      6  \n",
      "2 -0.058316      6  \n",
      "3 -0.024171      6  \n",
      "4 -0.077175      6  \n"
     ]
    }
   ],
   "source": [
    "# Reading/Loading the dataset files\n",
    "# Locate data directory \n",
    "possible_data_dirs = [\n",
    "    os.path.join(os.getcwd(), 'data'),\n",
    "    os.path.join(os.getcwd(), '..', 'data'),\n",
    "    os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "]\n",
    "\n",
    "data_dir = None\n",
    "for p in possible_data_dirs:\n",
    "    if os.path.exists(os.path.join(p, 'train.csv')) and os.path.exists(os.path.join(p, 'test.csv')):\n",
    "        data_dir = p\n",
    "        print(f\"Data directory found: {data_dir}\")\n",
    "        break\n",
    "\n",
    "if data_dir is None:\n",
    "    raise FileNotFoundError(\"Could not find data directory containing train.csv and test.csv\")\n",
    "\n",
    "train_path = os.path.join(data_dir, 'train.csv')\n",
    "test_path = os.path.join(data_dir, 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "# print the first 5 rows of the training data\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T17:22:43.147939Z",
     "iopub.status.busy": "2025-09-26T17:22:43.147848Z",
     "iopub.status.idle": "2025-09-26T17:22:43.987390Z",
     "shell.execute_reply": "2025-09-26T17:22:43.987157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rows: 90229, window_size: 362, windows: 249, remainder dropped: 91\n",
      "Train windows: (747, 75) Labels: (747,)\n",
      "X_train: (597, 75) X_val: (150, 75)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing step\n",
    "# 1) Parse timestamps and sort by time to preserve sequence\n",
    "train_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\n",
    "test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "train_df = train_df.sort_values('timestamp').reset_index(drop=True)\n",
    "test_df = test_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "SENSOR_COLS = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
    "TARGET_COL = 'label'\n",
    "\n",
    "# 2) Choose a window size that produces exactly 249 test windows\n",
    "NUM_TEST_WINDOWS = 249\n",
    "WINDOW_SIZE = len(test_df) // NUM_TEST_WINDOWS  # integer division\n",
    "print(f\"Test rows: {len(test_df)}, window_size: {WINDOW_SIZE}, windows: {NUM_TEST_WINDOWS}, remainder dropped: {len(test_df) - WINDOW_SIZE*NUM_TEST_WINDOWS}\")\n",
    "\n",
    "# 3) Feature engineering helpers\n",
    "import numpy as np\n",
    "\n",
    "def median_abs_deviation(values: np.ndarray) -> float:\n",
    "    med = np.median(values)\n",
    "    return float(np.median(np.abs(values - med)))\n",
    "\n",
    "def window_features(df_window: pd.DataFrame) -> dict:\n",
    "    feats = {}\n",
    "    n = len(df_window)\n",
    "    t = np.arange(n, dtype=np.float32)\n",
    "    for col in SENSOR_COLS:\n",
    "        x = df_window[col].to_numpy(dtype=np.float32, copy=False)\n",
    "        feats[f'{col}_mean'] = float(np.mean(x))\n",
    "        feats[f'{col}_std'] = float(np.std(x, ddof=1)) if n > 1 else 0.0\n",
    "        feats[f'{col}_min'] = float(np.min(x))\n",
    "        feats[f'{col}_max'] = float(np.max(x))\n",
    "        feats[f'{col}_median'] = float(np.median(x))\n",
    "        q25 = float(np.quantile(x, 0.25))\n",
    "        q75 = float(np.quantile(x, 0.75))\n",
    "        feats[f'{col}_q25'] = q25\n",
    "        feats[f'{col}_q75'] = q75\n",
    "        feats[f'{col}_iqr'] = q75 - q25\n",
    "        feats[f'{col}_mad'] = median_abs_deviation(x)\n",
    "        feats[f'{col}_abs_mean'] = float(np.mean(np.abs(x)))\n",
    "        feats[f'{col}_energy'] = float(np.mean(x*x))\n",
    "        # Linear trend (slope)\n",
    "        if n > 1:\n",
    "            slope = np.polyfit(t, x, 1)[0]\n",
    "        else:\n",
    "            slope = 0.0\n",
    "        feats[f'{col}_slope'] = float(slope)\n",
    "    # Simple cross-sensor correlations for aligned axes\n",
    "    for a_col, b_col, name in [\n",
    "        ('back_x','thigh_x','x'),\n",
    "        ('back_y','thigh_y','y'),\n",
    "        ('back_z','thigh_z','z'),\n",
    "    ]:\n",
    "        a = df_window[a_col].to_numpy(dtype=np.float32, copy=False)\n",
    "        b = df_window[b_col].to_numpy(dtype=np.float32, copy=False)\n",
    "        if n > 1 and np.std(a) > 0 and np.std(b) > 0:\n",
    "            corr = float(np.corrcoef(a, b)[0,1])\n",
    "        else:\n",
    "            corr = 0.0\n",
    "        feats[f'corr_back_thigh_{name}'] = corr\n",
    "    return feats\n",
    "\n",
    "\n",
    "def build_windows_features(df: pd.DataFrame, window_size: int, num_windows: int, with_labels: bool) -> tuple:\n",
    "    feature_rows = []\n",
    "    labels = [] if with_labels else None\n",
    "    for i in range(num_windows):\n",
    "        start = i * window_size\n",
    "        end = start + window_size\n",
    "        if end > len(df):\n",
    "            break\n",
    "        w = df.iloc[start:end]\n",
    "        feature_rows.append(window_features(w))\n",
    "        if with_labels:\n",
    "            # Use majority label within window\n",
    "            lbl = int(w[TARGET_COL].mode().iloc[0])\n",
    "            labels.append(lbl)\n",
    "    X = pd.DataFrame(feature_rows)\n",
    "    y = np.array(labels, dtype=np.int32) if with_labels else None\n",
    "    return X, y\n",
    "\n",
    "# 4) Build train windows (use same window size; drop trailing remainder)\n",
    "num_train_windows = len(train_df) // WINDOW_SIZE\n",
    "X_all, y_all = build_windows_features(train_df, WINDOW_SIZE, num_train_windows, with_labels=True)\n",
    "print('Train windows:', X_all.shape, 'Labels:', y_all.shape)\n",
    "\n",
    "# 5) Time-based split: last 20% windows as validation\n",
    "split_idx = int(0.8 * len(X_all))\n",
    "X_train, y_train = X_all.iloc[:split_idx].reset_index(drop=True), y_all[:split_idx]\n",
    "X_val, y_val = X_all.iloc[split_idx:].reset_index(drop=True), y_all[split_idx:]\n",
    "print('X_train:', X_train.shape, 'X_val:', X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"line-height:200%;color:#0099cc\">\n",
    "    Model Training\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-size:medium\">\n",
    "    Now that you have cleaned the data, it's time to train a model that can predict the target variable for this problem.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T17:22:43.988521Z",
     "iopub.status.busy": "2025-09-26T17:22:43.988448Z",
     "iopub.status.idle": "2025-09-26T17:22:44.326403Z",
     "shell.execute_reply": "2025-09-26T17:22:44.326158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained. Train windows: 597 Val windows: 150\n"
     ]
    }
   ],
   "source": [
    "# Model design\n",
    "# RandomForest baseline on window features\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample'\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "print('Model trained. Train windows:', len(X_train), 'Val windows:', len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRQUiByJquXB"
   },
   "source": [
    "<h3 style=\"line-height:200%;color:#0099cc\">\n",
    "    Evaluation Metric\n",
    "</h3>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-size:medium\">\n",
    "    The <code>F1 Score</code> is used to evaluate your model, with <code>macro</code> averaging. \n",
    "    To receive a score for this question, your model must have a minimum <code>F1 Score</code> of 0.40. In this case, the final score will be calculated based on the following formula:\n",
    "\n",
    "$$\\text{round}(f1score, 3) \\times 100$$\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-size:medium\">\n",
    "    If your model does not reach the minimum threshold, the received score will be zero.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T17:22:44.327460Z",
     "iopub.status.busy": "2025-09-26T17:22:44.327393Z",
     "iopub.status.idle": "2025-09-26T17:22:44.357902Z",
     "shell.execute_reply": "2025-09-26T17:22:44.357680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_f1_macro': 0.8135}\n"
     ]
    }
   ],
   "source": [
    "# evaluate your model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "val_pred = rf.predict(X_val)\n",
    "val_f1_macro = f1_score(y_val, val_pred, average='macro')\n",
    "print({'val_f1_macro': round(val_f1_macro, 4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaj4U85Pq5RY"
   },
   "source": [
    "<h2 style=\"line-height:200%;color:#0099cc\">\n",
    "    Prediction for Test Data and Output\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: left; line-height:200%; font-size:medium\">\n",
    "    Use your model to predict the samples in the test data and prepare the results in a table (<code>dataframe</code>) format as follows.\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align: center;line-height:200%;font-size:medium\">\n",
    "|Column|Description|\n",
    "|------|---|\n",
    "|label|Predicted movement type|\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlEKaA8qrAmX"
   },
   "source": [
    "<p style=\"text-align: left; line-height:200%; font-size:medium\">\n",
    "    The dataframe name must be <i>submission</i>; otherwise, the judging system will not be able to evaluate your attempt.\n",
    "    <br>\n",
    "    This dataframe contains only 1 column named <i>label</i> and has 249 rows.\n",
    "    <br>\n",
    "    For each row in the <i>test</i> dataframe, you must have one predicted value.\n",
    "    <br>\n",
    "    The table below shows the first 5 rows of the <code>submission</code> dataframe. However, in your answer, the values in the <i>label</i> column may differ.\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align: center;line-height:200%;font-size:medium\">\n",
    "|label|\n",
    "|-----|\n",
    "|1|\n",
    "|2|\n",
    "|1|\n",
    "|8|\n",
    "|8|\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T17:22:44.358991Z",
     "iopub.status.busy": "2025-09-26T17:22:44.358935Z",
     "iopub.status.idle": "2025-09-26T17:22:44.651672Z",
     "shell.execute_reply": "2025-09-26T17:22:44.651436Z"
    },
    "id": "j3exyIeeLIDS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test windows: (249, 75)\n",
      "Submission rows: 90229\n",
      "   label\n",
      "0      7\n",
      "1      7\n",
      "2      7\n",
      "3      7\n",
      "4      7\n"
     ]
    }
   ],
   "source": [
    "# predict test samples\n",
    "# Build fixed-count windows for test to match NUM_TEST_WINDOWS\n",
    "X_test, _ = build_windows_features(test_df, WINDOW_SIZE, NUM_TEST_WINDOWS, with_labels=False)\n",
    "print('Test windows:', X_test.shape)\n",
    "\n",
    "# Predict per-window labels\n",
    "y_test_pred = rf.predict(X_test).astype(int)\n",
    "\n",
    "# Expand window predictions to per-row labels\n",
    "num_rows = len(test_df)\n",
    "row_labels = np.empty(num_rows, dtype=int)\n",
    "for i in range(NUM_TEST_WINDOWS):\n",
    "    start = i * WINDOW_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    row_labels[start:end] = int(y_test_pred[i])\n",
    "\n",
    "# Handle remainder rows by predicting on the final partial window\n",
    "remainder = num_rows - WINDOW_SIZE * NUM_TEST_WINDOWS\n",
    "if remainder > 0:\n",
    "    leftover_df = test_df.iloc[WINDOW_SIZE * NUM_TEST_WINDOWS:]\n",
    "    leftover_feats = window_features(leftover_df)\n",
    "    leftover_X = pd.DataFrame([leftover_feats]).reindex(columns=X_test.columns, fill_value=0.0)\n",
    "    leftover_pred = int(rf.predict(leftover_X)[0])\n",
    "    row_labels[-remainder:] = leftover_pred\n",
    "\n",
    "submission = pd.DataFrame({'label': row_labels.astype(int)})\n",
    "print('Submission rows:', len(submission))\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwGtV9MzrLsz"
   },
   "source": [
    "<h2 style=\"line-height:200%;color:#0099cc\">\n",
    "    <b>Output Generation Cell</b>\n",
    "</h2>\n",
    "\n",
    "<p style=\"text-align: justify; line-height:200%; font-size:medium\">\n",
    "    Run the cell below to create the <code>result.zip</code> file. Please note that you must save the changes made in the notebook (<code>ctrl+s</code>) before running the cell below, so that your code can be reviewed if support is needed.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T17:22:44.652800Z",
     "iopub.status.busy": "2025-09-26T17:22:44.652725Z",
     "iopub.status.idle": "2025-09-26T17:22:44.669574Z",
     "shell.execute_reply": "2025-09-26T17:22:44.669332Z"
    },
    "id": "KT328lYmrM09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['movement_status.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'movement_status.ipynb')):\n",
    "    %notebook -e movement_status.ipynb\n",
    "\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "file_names = ['movement_status.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
